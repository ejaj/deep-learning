{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60572ae6",
   "metadata": {},
   "source": [
    "## Tensorflow ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe96283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d992d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'E': 1,\n",
       " 'N': 2,\n",
       " 'R': 3,\n",
       " 'a': 4,\n",
       " 'b': 5,\n",
       " 'c': 6,\n",
       " 'd': 7,\n",
       " 'e': 8,\n",
       " 'f': 9,\n",
       " 'g': 10,\n",
       " 'h': 11,\n",
       " 'i': 12,\n",
       " 'j': 13,\n",
       " 'k': 14,\n",
       " 'l': 15,\n",
       " 'm': 16,\n",
       " 'n': 17,\n",
       " 'o': 18,\n",
       " 'p': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Exploding and vanishing gradients is the  the major drawback of RNN\"\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_index = {char: i for i, char in enumerate(chars)}\n",
    "char_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bf7560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: 'E',\n",
       " 2: 'N',\n",
       " 3: 'R',\n",
       " 4: 'a',\n",
       " 5: 'b',\n",
       " 6: 'c',\n",
       " 7: 'd',\n",
       " 8: 'e',\n",
       " 9: 'f',\n",
       " 10: 'g',\n",
       " 11: 'h',\n",
       " 12: 'i',\n",
       " 13: 'j',\n",
       " 14: 'k',\n",
       " 15: 'l',\n",
       " 16: 'm',\n",
       " 17: 'n',\n",
       " 18: 'o',\n",
       " 19: 'p',\n",
       " 20: 'r',\n",
       " 21: 's',\n",
       " 22: 't',\n",
       " 23: 'v',\n",
       " 24: 'w',\n",
       " 25: 'x'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_char = {i: char for i, char in enumerate(chars)}\n",
    "index_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f82c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3\n",
    "sequences = []\n",
    "labels = []\n",
    " \n",
    "for i in range(len(text) - seq_length):\n",
    "    seq = text[i:i+seq_length]\n",
    "    label = text[i+seq_length]\n",
    "    sequences.append([char_to_index[char] for char in seq])\n",
    "    labels.append(char_to_index[label])\n",
    "# print(labels, sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f02207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 25, 19],\n",
       "       [25, 19, 15],\n",
       "       [19, 15, 18],\n",
       "       [15, 18,  7],\n",
       "       [18,  7, 12],\n",
       "       [ 7, 12, 17],\n",
       "       [12, 17, 10],\n",
       "       [17, 10,  0],\n",
       "       [10,  0,  4],\n",
       "       [ 0,  4, 17],\n",
       "       [ 4, 17,  7],\n",
       "       [17,  7,  0],\n",
       "       [ 7,  0, 23],\n",
       "       [ 0, 23,  4],\n",
       "       [23,  4, 17],\n",
       "       [ 4, 17, 12],\n",
       "       [17, 12, 21],\n",
       "       [12, 21, 11],\n",
       "       [21, 11, 12],\n",
       "       [11, 12, 17],\n",
       "       [12, 17, 10],\n",
       "       [17, 10,  0],\n",
       "       [10,  0, 10],\n",
       "       [ 0, 10, 20],\n",
       "       [10, 20,  4],\n",
       "       [20,  4,  7],\n",
       "       [ 4,  7, 12],\n",
       "       [ 7, 12,  8],\n",
       "       [12,  8, 17],\n",
       "       [ 8, 17, 22],\n",
       "       [17, 22, 21],\n",
       "       [22, 21,  0],\n",
       "       [21,  0, 12],\n",
       "       [ 0, 12, 21],\n",
       "       [12, 21,  0],\n",
       "       [21,  0, 22],\n",
       "       [ 0, 22, 11],\n",
       "       [22, 11,  8],\n",
       "       [11,  8,  0],\n",
       "       [ 8,  0,  0],\n",
       "       [ 0,  0, 22],\n",
       "       [ 0, 22, 11],\n",
       "       [22, 11,  8],\n",
       "       [11,  8,  0],\n",
       "       [ 8,  0, 16],\n",
       "       [ 0, 16,  4],\n",
       "       [16,  4, 13],\n",
       "       [ 4, 13, 18],\n",
       "       [13, 18, 20],\n",
       "       [18, 20,  0],\n",
       "       [20,  0,  7],\n",
       "       [ 0,  7, 20],\n",
       "       [ 7, 20,  4],\n",
       "       [20,  4, 24],\n",
       "       [ 4, 24,  5],\n",
       "       [24,  5,  4],\n",
       "       [ 5,  4,  6],\n",
       "       [ 4,  6, 14],\n",
       "       [ 6, 14,  0],\n",
       "       [14,  0, 18],\n",
       "       [ 0, 18,  9],\n",
       "       [18,  9,  0],\n",
       "       [ 9,  0,  3],\n",
       "       [ 0,  3,  2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f3a0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 18,  7, 12, 17, 10,  0,  4, 17,  7,  0, 23,  4, 17, 12, 21, 11,\n",
       "       12, 17, 10,  0, 10, 20,  4,  7, 12,  8, 17, 22, 21,  0, 12, 21,  0,\n",
       "       22, 11,  8,  0,  0, 22, 11,  8,  0, 16,  4, 13, 18, 20,  0,  7, 20,\n",
       "        4, 24,  5,  4,  6, 14,  0, 18,  9,  0,  3,  2,  2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0568f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 02:11:12.047194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-01 02:11:12.151634: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "X_one_hot = tf.one_hot(X, len(chars))\n",
    "y_one_hot = tf.one_hot(y, len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef7f59",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef36ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(seq_length, len(chars)), activation='relu'))\n",
    "model.add(Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3e65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d7c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2762 - accuracy: 0.0312\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2556 - accuracy: 0.0312\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2373 - accuracy: 0.0312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2197 - accuracy: 0.0469\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2028 - accuracy: 0.0469\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1860 - accuracy: 0.0781\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1691 - accuracy: 0.0938\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1520 - accuracy: 0.1094\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1345 - accuracy: 0.1406\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1178 - accuracy: 0.1719\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1005 - accuracy: 0.1719\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0828 - accuracy: 0.1875\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0652 - accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0454 - accuracy: 0.2656\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0261 - accuracy: 0.2812\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0060 - accuracy: 0.2969\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9848 - accuracy: 0.3125\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9620 - accuracy: 0.3594\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9396 - accuracy: 0.3750\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9139 - accuracy: 0.3906\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8882 - accuracy: 0.4375\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8605 - accuracy: 0.4219\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8325 - accuracy: 0.3750\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8001 - accuracy: 0.3906\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7707 - accuracy: 0.4062\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7353 - accuracy: 0.4219\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7015 - accuracy: 0.3906\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6660 - accuracy: 0.3594\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6285 - accuracy: 0.3438\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5927 - accuracy: 0.3438\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5544 - accuracy: 0.3281\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5156 - accuracy: 0.2812\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4763 - accuracy: 0.2969\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4381 - accuracy: 0.2969\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4021 - accuracy: 0.2969\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3663 - accuracy: 0.2812\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3315 - accuracy: 0.2812\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2957 - accuracy: 0.3125\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2631 - accuracy: 0.3125\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2279 - accuracy: 0.3125\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1930 - accuracy: 0.3281\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1576 - accuracy: 0.3281\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1220 - accuracy: 0.3438\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0856 - accuracy: 0.3906\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0484 - accuracy: 0.4531\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0127 - accuracy: 0.4688\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9769 - accuracy: 0.4844\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9393 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9032 - accuracy: 0.5156\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8660 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8293 - accuracy: 0.5625\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7919 - accuracy: 0.5781\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7196 - accuracy: 0.5938\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6827 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6468 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6090 - accuracy: 0.5781\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5720 - accuracy: 0.5938\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5358 - accuracy: 0.6094\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4996 - accuracy: 0.6562\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4622 - accuracy: 0.6719\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.6875\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3906 - accuracy: 0.6875\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3545 - accuracy: 0.7031\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3196 - accuracy: 0.7344\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2497 - accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2151 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1809 - accuracy: 0.7656\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1472 - accuracy: 0.7969\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1134 - accuracy: 0.8281\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0793 - accuracy: 0.8438\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.8438\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.8594\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.8594\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9538 - accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8942 - accuracy: 0.8750\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8648 - accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.8906\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.8906\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.8906\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.8906\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.8906\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.9062\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.9062\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.9062\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.9062\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.9219\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.9375\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.9375\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.9375\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.9375\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9375\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.9531\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.9531\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a605041c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_one_hot, y_one_hot, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97bfa9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Generated Text:\n",
      "Exploding and vanishing and vanishing and vanishing and vanishing and vani\n"
     ]
    }
   ],
   "source": [
    "start_seq = \"Exploding and vanishing \"\n",
    "generated_text = start_seq\n",
    " \n",
    "for i in range(50):\n",
    "    x = np.array([[char_to_index[char] for char in generated_text[-seq_length:]]])\n",
    "    x_one_hot = tf.one_hot(x, len(chars))\n",
    "    prediction = model.predict(x_one_hot)\n",
    "    next_index = np.argmax(prediction)\n",
    "    next_char = index_to_char[next_index]\n",
    "    generated_text += next_char\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3429d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import one_hot, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2c19e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 25, 19],\n",
       "        [25, 19, 15],\n",
       "        [19, 15, 18],\n",
       "        [15, 18,  7],\n",
       "        [18,  7, 12],\n",
       "        [ 7, 12, 17],\n",
       "        [12, 17, 10],\n",
       "        [17, 10,  0],\n",
       "        [10,  0,  4],\n",
       "        [ 0,  4, 17],\n",
       "        [ 4, 17,  7],\n",
       "        [17,  7,  0],\n",
       "        [ 7,  0, 23],\n",
       "        [ 0, 23,  4],\n",
       "        [23,  4, 17],\n",
       "        [ 4, 17, 12],\n",
       "        [17, 12, 21],\n",
       "        [12, 21, 11],\n",
       "        [21, 11, 12],\n",
       "        [11, 12, 17],\n",
       "        [12, 17, 10],\n",
       "        [17, 10,  0],\n",
       "        [10,  0, 10],\n",
       "        [ 0, 10, 20],\n",
       "        [10, 20,  4],\n",
       "        [20,  4,  7],\n",
       "        [ 4,  7, 12],\n",
       "        [ 7, 12,  8],\n",
       "        [12,  8, 17],\n",
       "        [ 8, 17, 22],\n",
       "        [17, 22, 21],\n",
       "        [22, 21,  0],\n",
       "        [21,  0, 12],\n",
       "        [ 0, 12, 21],\n",
       "        [12, 21,  0],\n",
       "        [21,  0, 22],\n",
       "        [ 0, 22, 11],\n",
       "        [22, 11,  8],\n",
       "        [11,  8,  0],\n",
       "        [ 8,  0,  0],\n",
       "        [ 0,  0, 22],\n",
       "        [ 0, 22, 11],\n",
       "        [22, 11,  8],\n",
       "        [11,  8,  0],\n",
       "        [ 8,  0, 16],\n",
       "        [ 0, 16,  4],\n",
       "        [16,  4, 13],\n",
       "        [ 4, 13, 18],\n",
       "        [13, 18, 20],\n",
       "        [18, 20,  0],\n",
       "        [20,  0,  7],\n",
       "        [ 0,  7, 20],\n",
       "        [ 7, 20,  4],\n",
       "        [20,  4, 24],\n",
       "        [ 4, 24,  5],\n",
       "        [24,  5,  4],\n",
       "        [ 5,  4,  6],\n",
       "        [ 4,  6, 14],\n",
       "        [ 6, 14,  0],\n",
       "        [14,  0, 18],\n",
       "        [ 0, 18,  9],\n",
       "        [18,  9,  0],\n",
       "        [ 9,  0,  3],\n",
       "        [ 0,  3,  2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(sequences)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c4609c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 18,  7, 12, 17, 10,  0,  4, 17,  7,  0, 23,  4, 17, 12, 21, 11, 12,\n",
       "        17, 10,  0, 10, 20,  4,  7, 12,  8, 17, 22, 21,  0, 12, 21,  0, 22, 11,\n",
       "         8,  0,  0, 22, 11,  8,  0, 16,  4, 13, 18, 20,  0,  7, 20,  4, 24,  5,\n",
       "         4,  6, 14,  0, 18,  9,  0,  3,  2,  2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(labels)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50d1699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = one_hot(X, num_classes=len(chars)).float()\n",
    "y_one_hot = one_hot(y, num_classes=len(chars)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f9db182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70d9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model build\n",
    "model = SimpleRNNModel(input_size=len(chars), hidden_size=50, output_size=len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9388f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39c21774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.1915154457092285\n",
      "Epoch [20/100], Loss: 3.1152400970458984\n",
      "Epoch [30/100], Loss: 2.996299982070923\n",
      "Epoch [40/100], Loss: 2.8263099193573\n",
      "Epoch [50/100], Loss: 2.7296624183654785\n",
      "Epoch [60/100], Loss: 2.6324095726013184\n",
      "Epoch [70/100], Loss: 2.520597457885742\n",
      "Epoch [80/100], Loss: 2.372476816177368\n",
      "Epoch [90/100], Loss: 2.181813955307007\n",
      "Epoch [100/100], Loss: 1.9495078325271606\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_one_hot)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ff7a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Exploding and vanishing ani a i                                           \n"
     ]
    }
   ],
   "source": [
    "# Text generation\n",
    "model.eval()\n",
    "generated_text = \"Exploding and vanishing \"\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(50):\n",
    "        x = torch.tensor([[char_to_index[char] for char in generated_text[-seq_length:]]])\n",
    "        x_one_hot = one_hot(x, num_classes=len(chars)).float()\n",
    "        outputs = model(x_one_hot)\n",
    "        _, predicted_index = torch.max(outputs, -1)\n",
    "        next_char = index_to_char[predicted_index.item()]\n",
    "        generated_text += next_char\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea018ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
